\section{Implementation}
\label{sec:implement}

The interpreter for the Gryph Programming Language,
implemented in Haskell language during this semester, comprises three
main steps: \textbf{lexical analysis}, for tokens discovery;
\textbf{syntactic analysis}, for language constructs
identification; and \textbf{program execution}, for
performing machine state changes according to the
meaning of the parsed entities, given by the semantic
rules of the language (see Section \ref{sec:usage}). The following subsections
present them with rich detail.

\subsection{Lexical analysis}

Lexical analysis is the part of the task of analysing syntax
which deals with small-scale constructs. Dealing with it
separately is justified by gains in terms of simplicity, since
it uses simple techniques (pattern matching, essentially); efficiency, since it is
more suitable for optimization than the general syntactic parser; 
and portability, since lexical analysers can be platform dependent, in contrast
with syntax analysers, which can be made independent.

In order to simplify the development, \textbf{Alex}\footnote{https://www.haskell.org/alex/}, a lexical
analyzer generator for Haskell, was used. It is basically built
upon a sequence of regular expressions which describes the 
language tokens. The implemented lexical analyzer takes a program as input and produces
a list of the identified tokens, which is then transmitted to the
syntactic parser, described in the next subsection. Alex also furnishes
the position (line and column) of each token, for further richier error reporting, but
this version of the interpreter does not take it into account.

\subsection{Syntactic analysis}

The syntactic analyzer deals with the large-scale constructs, 
such as expressions, statements and subprogram definitions.
It takes the list of tokens produced in the lexical
analysis and the language grammar (generally in Bakus-Naur Form) and performs
the syntactic parsing according to its productions.
Some adjustments may be necessary in order
to adequate the grammar rules to the some restrictions imposed by
the adopted parsing algorithm.

Syntactic analysis, in the implemented interpreter, is performed
with the aid of the \textbf{Parsec}\footnote{http://hackage.haskell.org/package/parsec} 
parser library for Haskell.
Parsec is based on \emph{monadic parser combinators}, and is
fast, safe, well-documented and highly customizable. Basically,
developing a parser with this tool is a matter of writing and combining small parsers
for each grammar construct, taking care with left-recursive
productions, since the underlying algorithm doesn't 
accept them.

The output of the syntactic parser in this implementation is a syntactic tree
represented by Haskell user-defined types. The most general constructs are called
\textbf{program units}, which are abstractions for import commands, subprogram definitions,
struct definitions and statements. The Haskell type defined to represent such
concept was:

\begin{lstlisting}[language=Haskell,basicstyle=\footnotesize]
data ProgramUnit =  Stmt Stmt | 
                    SubprogramDecl Subprogram |
                    StructDecl StructDecl |
                    Use String 
deriving (Show, Eq)
\end{lstlisting}

Therefore, a program is just a sequence of program units. Statements, in turn,
are the basic execution units in a program, and can assume various forms,
like control structures, arithmetic expressions, variable declaration and
assignment commands. The type defined for representing statements was:

\begin{lstlisting}[language=Haskell,basicstyle=\footnotesize]
data Stmt = ReadStmt Identifier | 
            PrintStmt ArithExpr | 
            PrintLnStmt ArithExpr | 
            DeclStmt VarDeclaration | 
            AttrStmt [ArithExpr] [ArithExpr] |
            SubCallStmt SubprogCall |
            IfStmt ArithExpr IfBody ElseBody |
            ReturnStmt (Maybe ArithExpr) |
            ForStmt [Identifier] [ArithExpr] Block |
            WhileStmt ArithExpr Block |
            BfsStmt [Identifier] ArithExpr (Maybe ArithExpr) Block |
            DfsStmt [Identifier] ArithExpr (Maybe ArithExpr) Block |
            AddStmt ArithExpr ArithExpr |
            AddEdgeStmt (Maybe ArithExpr) Edge ArithExpr |
            DelStmt ArithExpr ArithExpr |
            DelEdgeStmt Edge ArithExpr |
            BreakStmt 
deriving (Show, Eq) 
\end{lstlisting}

The listing above shows the general approach of representing each
language construct with values of custom Haskell types.
It's worth noting that the type {\texttt ArithExpr}
appears frequently, since it represents any valid expression, as 
showed by its type definition:

\begin{lstlisting}[language=Haskell,basicstyle=\footnotesize]
data ArithExpr =    ArithUnExpr ArithUnOp ArithExpr | 
                    ArithBinExpr ArithBinOp ArithExpr ArithExpr | 
                    ArithTerm Term |
                    ExprLiteral ExprLiteral |
                    GraphAccess ArithExpr ArithExpr |
                    GraphEdgeAccess ArithExpr Edge |
                    DictAccess ArithExpr ArithExpr |
                    ListAccess ArithExpr ArithExpr |
                    StructAccess ArithExpr Identifier |
                    TupleAccess ArithExpr ArithExpr |
                    CastExpr ArithExpr GType |
                    ArithRelExpr RelOp ArithExpr ArithExpr |
                    ArithEqExpr EqOp ArithExpr ArithExpr |
                    LogicalBinExpr BoolBinOp ArithExpr ArithExpr |
                    StructInitExpr StructInit
deriving (Show, Eq)
\end{lstlisting}

In this way, every syntactically correct program becomes a list
of program units, which, in turn, are values defined over other
Haskell types. For example, consider the following Gryph valid program,
which prints the sum of two declared and initialized variables:

\begin{lstlisting}[language=Gryph]
a : int = 10;
b : int = 30;
println a+b;
\end{lstlisting}

The corresponding output of the syntactic analysis is:

\begin{lstlisting}[language=Haskell,basicstyle=\scriptsize]
[Stmt (DeclStmt (VarDeclaration [Ident "a"] GInteger [ArithTerm 
(LitTerm (Lit 10))])), Stmt (DeclStmt (VarDeclaration [Ident "b"] 
GInteger [ArithTerm (LitTerm (Lit 30))])), Stmt (PrintLnStmt 
(ArithBinExpr PlusBinOp (ArithTerm (IdTerm (Ident "a"))) 
(ArithTerm (IdTerm (Ident "b")))))]
\end{lstlisting}

The complete list of types defined for representing syntactic
entities can be found in the module {\texttt Syntactic.Syntax}
of the interpreter. Finally, after the syntactic analysis, the list of program units
is processed, in order to execute the semantic rules
of the language and change the machine state for performing
computation. 

\subsection{Program execution}

\subsubsection{Auxiliary structures}

Some data structures were used to simulate the data and
program memory, as well as the current scope stack
during a program execution. 

\paragraph{Memory}

The memory structure intends to store the variables
attributes during program execution. It is represented
by a Data.Map in Haskell, which is an effecient implementation
of a dictionary, having the following definition:

\begin{lstlisting}[language=Gryph, basicstyle=\footnotesize]
type Memory = M.Map CellIdentifier Cell
\end{lstlisting}

A {\texttt CellIdentifier} is a pair containg
the name and scope of a variable, and the Cell
is another pair, storing a type and a memory value.
There is a difference between memory values and
common values of the language, since
the memory can also contain reference (a CellIdentifier)
to other variables in memory.

\paragraph{Program Memory}

The program memory stores subprogram and struct definitions.
So, it is intented to keep a parsed Gryph code. The
following type definitions clarify how this was
implemented:

\begin{lstlisting}[language=Gryph, basicstyle=\footnotesize]
type ProgramMemory = M.Map UnitIdentifier UnitContent
data UnitIdentifier =   SubIdentifier SubIdentifier | 
                        StructIdentifier StructIdentifier deriving (Eq, Show, Ord)
data UnitContent =  SubContent SubContent | 
                    StructContent StructContent deriving (Eq, Show)
\end{lstlisting}


\paragraph{Scope stack}

The scope stack is intented to point to the current
context of the program execution. It is important
since it defines the referencing environments during
execution. Values inside this stack are of type 
{\texttt Scope}, whose definition is:

\begin{lstlisting}[language=Gryph, basicstyle=\footnotesize]
data Scope =    GlobalScope | 
                SubScope Integer | 
                IterationScope Integer | 
                BlockScope Integer deriving (Eq, Show, Ord)
\end{lstlisting}

Differentiating the types of scopes is important to allow the correct execution of 
return and break statements. For example, a return statement searches for the
last SubScope, to move the execution flow outside the last called subprogram.

\subsubsection{Execution}

The input of the execution phase is a list of program units. The {\texttt exec}
function is responsible for processing it, as indicated by its
signature:

\begin{lstlisting}[language=Haskell, basicstyle=\footnotesize]
exec :: Memory -> ProgramMemory -> Scopes -> [ProgramUnit] -> 
                                IO(Memory, ProgramMemory, Scopes) 
\end{lstlisting}

Each unit is processed by the function {\texttt execUnit}, whose signature is:

\begin{lstlisting}[language=Haskell, basicstyle=\footnotesize]
execUnit :: ProgramUnit -> Memory -> ProgramMemory -> 
                    Scopes -> IO (Memory, ProgramMemory, Scopes)
\end{lstlisting}

The processing is based in pattern matching based on the value constructors
of the types presented in the previous subsection. The definition of the
{\texttt execUnit} function demonstrates how this works:

\begin{lstlisting}[language=Haskell, basicstyle=\footnotesize]
execUnit (SubprogramDecl sub) m pm ss = 
                do 
                    pm' <- execSubDecl sub m pm ss
                    return $ (m, pm', ss)
execUnit (StructDecl struct) m pm ss = 
                do
                    pm' <- execStructDecl m pm ss struct
                    return $ (m, pm', ss)

execUnit (Stmt stmt) m pm ss = 
                do 
                    (m', ss', v) <- execStmt stmt m pm ss
                    return $ (m', pm, ss')
execUnit (Use path) m pm ss = 
                do
                    f <- parseFile path
                    let decls = filter (\x -> case x of    
                                                (Use _) -> False
                                                (Stmt _) -> False
                                                _ -> True) f
                    exec m pm ss decls
\end{lstlisting}

Similar definitions occur throughout the {\texttt Execution.Semantic} module, 
which is responsible for the execution step. It is important to notice
that the (data) memory, the program memory and the stack of scopes
are always transmitted function to function, allowing the communication
of the effects of the statements over the machine state and the
program execution flow. The following sections details some other important aspects of 
the implementation.

\paragraph{Condition for statement execution in blocks}

Before each execution of a statement inside a block, it is checked if
the scope introduced in the block entrance is the same as the
current scope (the top of the scope stack). This is done to
allow returns and breaks to work properly: such statements
causes the scope stack to change, which, by the mentioned condition, makes
the execution of the subsequent statements doesn't occur.

\paragraph{Graph representation}

A custom type was defined for the representation of graphs in Gryph. 
This was done to allow graphs holding loads of any types in its vertices and
edges, enhancing the power of this data structure in the contexts of
the language domain. Below is the Haskell definition:

\begin{lstlisting}[language=Haskell, basicstyle=\footnotesize]
data Vertex a = Vertex Int a
data Edge a b = Edge (Vertex a) (Vertex a) b
data Graph a b = Graph (S.Set (Vertex a)) (M.Map Int [Edge a b]) 
                    deriving (Eq, Ord)
\end{lstlisting}

A graph is then a set of vertex internally identified by integers holding some type $a$, together with
a map of vertexes identifiers to edges connecting vertexes of type $a$ and holding data (weight)
of type $b$. This map is actually a representation of the graph adjacency list. 
In this way, any type of the language can be put inside vertexes and
edges, increasing the range of possible applications.


